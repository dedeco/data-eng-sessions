{
 "cells": [
  {
   "cell_type": "raw",
   "id": "686557ce-13a9-4960-aa1f-2df432616ded",
   "metadata": {},
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a7ba82-c6de-4e0e-a925-4d2b6ec616ab",
   "metadata": {},
   "source": [
    "# Cálculo de eligibilidade \n",
    "\n",
    "Descrição: Esse notebook faz o cálculo de eligibilidade para projeto NBA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed6e711-ae70-48ba-b816-13683f336d71",
   "metadata": {},
   "source": [
    "## Inicializar variáveis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c94d72-2627-407c-9c49-f2edb518dded",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: IS_TESTING=\"Yes\"\n",
      "env: CREATE_DATAPROC_CLUSTER=None\n"
     ]
    }
   ],
   "source": [
    "%env IS_TESTING=\"Yes\"\n",
    "%env CREATE_DATAPROC_CLUSTER=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48fb2cb-73d3-4974-898a-d9b6c8f3a778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"<PROJECT_ID>\" \n",
    "!gcloud config set project {PROJECT_ID}     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcfbcb7-609c-40fa-84e5-9cb5f71c17c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Instalação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57106d85-b0ff-45c7-9f00-76fe9405f70a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-13 16:04:13--  https://builds.openlogic.com/downloadJDK/openlogic-openjdk/8u332-b09/openlogic-openjdk-8u332-b09-linux-x64.tar.gz\n",
      "Resolving builds.openlogic.com (builds.openlogic.com)... 13.32.164.58, 13.32.164.69, 13.32.164.34, ...\n",
      "Connecting to builds.openlogic.com (builds.openlogic.com)|13.32.164.58|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 105558622 (101M) [application/x-gzip]\n",
      "Saving to: ‘/tmp/java/openlogic-openjdk-8u332-b09-linux-x64.tar.gz’\n",
      "\n",
      "openlogic-openjdk-8 100%[===================>] 100.67M   229MB/s    in 0.4s    \n",
      "\n",
      "2024-06-13 16:04:14 (229 MB/s) - ‘/tmp/java/openlogic-openjdk-8u332-b09-linux-x64.tar.gz’ saved [105558622/105558622]\n",
      "\n",
      "/tmp/java/openlogic-openjdk-8u332-b09-linux-x64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    \"\"\"\n",
    "    The testing suite does not currently support testing on Dataproc clusters,\n",
    "    so the testing environment is setup to replicate Dataproc via the following steps.\n",
    "    \"\"\"\n",
    "    JAVA_VER = \"8u332-b09\"\n",
    "    JAVA_FOLDER = \"/tmp/java\"\n",
    "    FILE_NAME = f\"openlogic-openjdk-{JAVA_VER}-linux-x64\"\n",
    "    TAR_FILE = f\"{JAVA_FOLDER}/{FILE_NAME}.tar.gz\"\n",
    "    DOWNLOAD_LINK = f\"https://builds.openlogic.com/downloadJDK/openlogic-openjdk/{JAVA_VER}/openlogic-openjdk-{JAVA_VER}-linux-x64.tar.gz\"\n",
    "    PYSPARK_VER = \"3.1.3\"\n",
    "\n",
    "    # Download Open JDK 8. Spark requires Java to execute.\n",
    "    ! rm -rf $JAVA_FOLDER\n",
    "    ! mkdir $JAVA_FOLDER\n",
    "    ! wget -P $JAVA_FOLDER $DOWNLOAD_LINK\n",
    "    os.environ[\"JAVA_HOME\"] = f\"{JAVA_FOLDER}/{FILE_NAME}\"\n",
    "    ! tar -zxf $TAR_FILE -C $JAVA_FOLDER\n",
    "    ! echo $JAVA_HOME\n",
    "\n",
    "    # Pin the Spark version to match that the Dataproc 2.0 cluster.\n",
    "    ! pip install pyspark==$PYSPARK_VER -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ed12b-c180-40ac-88d2-365779151d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"CREATE_DATAPROC_CLUSTER\"):\n",
    "    !gcloud dataproc clusters create \"data-eng-bv-cluster\" \\\n",
    "        --region=us-central1 \\\n",
    "        --enable-component-gateway \\\n",
    "        --image-version=2.0 \\\n",
    "        --optional-components=JUPYTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e2403-7e63-4252-b110-9ac264914aa4",
   "metadata": {},
   "source": [
    "## Passos de Transformação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b5707b-a134-4286-bf3e-58d41380051a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. **Spark Session:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7490859-15d5-4aba-94de-6f83119e6b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6f0563-9cbd-484d-8efb-da96737dad34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/13 16:04:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Initialize the \"SparkSession\" with the following config.\n",
    "VER = \"0.26.0\"\n",
    "FILE_NAME = f\"spark-bigquery-with-dependencies_2.12-{VER}.jar\"\n",
    "\n",
    "if os.getenv(\"IS_TESTING\"):\n",
    "    connector = f\"https://github.com/GoogleCloudDataproc/spark-bigquery-connector/releases/download/{VER}/{FILE_NAME}\"\n",
    "else:\n",
    "    connector = f\"gs://spark-lib/bigquery/{FILE_NAME}\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"spark-bigquery-data-eng-sessions-demo\")\n",
    "    .config(\"spark.jars\", connector)\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", \"500\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ddb93d-2c69-4976-85b0-2f5f2752eb95",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. **Carga de dados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d13c2b-5f3c-4dd8-918f-e4b373491ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "account_data = [(\"ACC001\", \"BANK01\", \"P001\"),\n",
    "                (\"ACC002\", \"BANK01\", \"P002\"),\n",
    "                (\"ACC003\", \"BANK02\", \"P003\")]\n",
    "account_schema = [\"account_id\", \"bank_id\", \"party_id\"]\n",
    "account_df = spark.createDataFrame(data=account_data, schema=account_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9a3eec-fe88-4e65-acef-0978998e0825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "party_data = [(\"P001\", \"hashed_name1\", 35, \"other_data1\"),\n",
    "              (\"P002\", \"hashed_name2\", 75, \"other_data2\"),\n",
    "              (\"P003\", \"hashed_name3\", 22, \"other_data3\")]\n",
    "party_schema = [\"party_id\", \"hashed_name\", \"age\", \"other_customer_data\"]\n",
    "party_df = spark.createDataFrame(data=party_data, schema=party_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884ae6a7-e56c-4215-b989-f3821144bc12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_data = [(\"PROD01\", \"Car Loan\"),\n",
    "                (\"PROD02\", \"Solar Equipment Loan\"),\n",
    "                (\"PROD03\", \"Credit Line\")]\n",
    "product_schema = [\"product_id\", \"product_name\"]\n",
    "product_df = spark.createDataFrame(data=product_data, schema=product_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16398811-9231-4186-9aad-786a109f6db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_vs_party_data = [\n",
    "('P001', 'PROD01', 'Car Loan', 30000, 720, '2023-12-25'),\n",
    "('P001', 'PROD02', 'Solar Equipment Loan', 15000, 720, '2024-01-15'),\n",
    "('P002', 'PROD01', 'Car Loan', 25000, 630, '2024-02-14'),\n",
    "('P003', 'PROD03', 'Credit Line', 10000, 580, '2024-03-17'),\n",
    "]\n",
    "\n",
    "product_vs_party_schema = [\n",
    "    \"party_id\", \n",
    "    \"product_id\", \n",
    "    \"product_name\", \n",
    "    \"loan_amount\", \n",
    "    \"credit_score\",\n",
    "    \"event_date\"\n",
    "]\n",
    "\n",
    "product_vs_party_df = spark.createDataFrame(data=product_vs_party_data, schema=product_vs_party_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b120361-cd3b-4c83-a5f1-48f07fcdc23a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. **Definindo as transformações:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a636ce-7628-4ca0-b60e-fc2a99aa24b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join product_vs_party_df with party_df to get age information\n",
    "joined_df = product_vs_party_df.join(party_df, \"party_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b6428f2-a6e8-4bdb-b1b4-14801fa01696",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jupyter\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: rules\n",
      "  Building wheel for rules (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rules: filename=rules-1.3-py3-none-any.whl size=1675 sha256=c029bf5cf874a2c9dd1e0b4bce273e0753737b44846e94387c4e6ca1db8ea71c\n",
      "  Stored in directory: /var/tmp/pip-ephem-wheel-cache-87xx19_k/wheels/a5/eb/36/799b873945ed0b79b38fc9a1580abda5f4e3699c5c138d7fa9\n",
      "Successfully built rules\n",
      "Installing collected packages: rules\n",
      "  Attempting uninstall: rules\n",
      "    Found existing installation: rules 1.3\n",
      "    Uninstalling rules-1.3:\n",
      "      Successfully uninstalled rules-1.3\n",
      "Successfully installed rules-1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "151281db-f36e-4590-b210-a87f4f35922f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.addFile('/home/jupyter/eligibility/rules.py') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f41d374e-be91-48bc-aa72-77cbed803a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from eligibility.rules import is_eligible_age_udf, has_recent_car_loan_udf\n",
    "from pyspark.sql.functions import avg, col, count, desc, round, size, udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3345826-2c84-4f61-aa41-639c6dd6dd41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+-----------+------------+----------+------------+---+-------------------+\n",
      "|party_id|product_id|        product_name|loan_amount|credit_score|event_date| hashed_name|age|other_customer_data|\n",
      "+--------+----------+--------------------+-----------+------------+----------+------------+---+-------------------+\n",
      "|    P003|    PROD03|         Credit Line|      10000|         580|2024-03-17|hashed_name3| 22|        other_data3|\n",
      "|    P002|    PROD01|            Car Loan|      25000|         630|2024-02-14|hashed_name2| 75|        other_data2|\n",
      "|    P001|    PROD01|            Car Loan|      30000|         720|2023-12-25|hashed_name1| 35|        other_data1|\n",
      "|    P001|    PROD02|Solar Equipment Loan|      15000|         720|2024-01-15|hashed_name1| 35|        other_data1|\n",
      "+--------+----------+--------------------+-----------+------------+----------+------------+---+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453081a-f8fb-43f2-b2f1-a113c8ccbf7e",
   "metadata": {},
   "source": [
    "#### Idade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47484efc-444b-43c3-b9ec-6c5106cbf9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_df = joined_df.withColumn(\"eligible_age\", is_eligible_age_udf(col(\"age\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4e54a09-2dd3-44d5-8561-2dae2ff0e277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:=================================================>      (66 + 4) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+-----------+------------+----------+------------+---+-------------------+------------+\n",
      "|party_id|product_id|        product_name|loan_amount|credit_score|event_date| hashed_name|age|other_customer_data|eligible_age|\n",
      "+--------+----------+--------------------+-----------+------------+----------+------------+---+-------------------+------------+\n",
      "|    P003|    PROD03|         Credit Line|      10000|         580|2024-03-17|hashed_name3| 22|        other_data3|        true|\n",
      "|    P002|    PROD01|            Car Loan|      25000|         630|2024-02-14|hashed_name2| 75|        other_data2|       false|\n",
      "|    P001|    PROD01|            Car Loan|      30000|         720|2023-12-25|hashed_name1| 35|        other_data1|        true|\n",
      "|    P001|    PROD02|Solar Equipment Loan|      15000|         720|2024-01-15|hashed_name1| 35|        other_data1|        true|\n",
      "+--------+----------+--------------------+-----------+------------+----------+------------+---+-------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "eligible_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe315acd-c22a-4649-8b54-eec2e6894ded",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tem financiamento de carro nos últimos 90 dias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31aae75d-e22c-4440-919e-2a0f83744c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eligible_df = eligible_df.withColumn(\"eligible_has_loan_car\", has_recent_car_loan_udf(col(\"product_name\"),col(\"event_date\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53dd7abc-69ee-4d76-be22-57684ec1e513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:=======================================================>(74 + 1) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+-----------+------------+----------+------------+---+-------------------+------------+---------------------+\n",
      "|party_id|product_id|        product_name|loan_amount|credit_score|event_date| hashed_name|age|other_customer_data|eligible_age|eligible_has_loan_car|\n",
      "+--------+----------+--------------------+-----------+------------+----------+------------+---+-------------------+------------+---------------------+\n",
      "|    P003|    PROD03|         Credit Line|      10000|         580|2024-03-17|hashed_name3| 22|        other_data3|        true|                false|\n",
      "|    P002|    PROD01|            Car Loan|      25000|         630|2024-02-14|hashed_name2| 75|        other_data2|       false|                false|\n",
      "|    P001|    PROD01|            Car Loan|      30000|         720|2023-12-25|hashed_name1| 35|        other_data1|        true|                false|\n",
      "|    P001|    PROD02|Solar Equipment Loan|      15000|         720|2024-01-15|hashed_name1| 35|        other_data1|        true|                false|\n",
      "+--------+----------+--------------------+-----------+------------+----------+------------+---+-------------------+------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "eligible_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee685f8-7628-4c03-ba8e-f58aac945b3b",
   "metadata": {},
   "source": [
    "#### 4. Salvando Data transformado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8dc778c-7450-4a07-953b-b47e196f4f23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-------------------+------------+---------------------+\n",
      "|party_id| hashed_name|other_customer_data|eligible_age|eligible_has_loan_car|\n",
      "+--------+------------+-------------------+------------+---------------------+\n",
      "|    P003|hashed_name3|        other_data3|        true|                false|\n",
      "|    P002|hashed_name2|        other_data2|       false|                false|\n",
      "|    P001|hashed_name1|        other_data1|        true|                false|\n",
      "+--------+------------+-------------------+------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "columns_to_keep = [\"party_id\", \"hashed_name\", \"other_customer_data\", \"eligible_age\", \"eligible_has_loan_car\"]\n",
    "\n",
    "# Filter and group by 'party_id', taking the first value per column\n",
    "aggregated_df = eligible_df.select(columns_to_keep).groupBy(\"party_id\").agg(\n",
    "    *[F.first(col).alias(col) for col in columns_to_keep[1:]]\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "aggregated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af3da3-8596-489a-b6e2-5c632c6be662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
